{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Sentiment_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTCnQf4NdfqeOm79K0nJfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c523916f1934508834340818347160b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b6f5f3246ac4a5687892572c92fa021",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c93c88138cec49ec99aab0e363339634",
              "IPY_MODEL_6b276f1155364f2690b624fedb3a15c1"
            ]
          }
        },
        "2b6f5f3246ac4a5687892572c92fa021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c93c88138cec49ec99aab0e363339634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0381fad6d1343bf892becbc917b02c6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b6996ca8e294ad998ad2d3b8d23d079"
          }
        },
        "6b276f1155364f2690b624fedb3a15c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd74c9260ee94deaa8420fbe57f95717",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a9c0672340a4c14a106779415fb3593"
          }
        },
        "b0381fad6d1343bf892becbc917b02c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b6996ca8e294ad998ad2d3b8d23d079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd74c9260ee94deaa8420fbe57f95717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a9c0672340a4c14a106779415fb3593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/NLP/blob/master/Bert/Bert_Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zRHuZh-9UeX"
      },
      "source": [
        "- Huggingface  \r\n",
        "- Pytorch  \r\n",
        "- CoLA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkMLeJQbKhoY"
      },
      "source": [
        "**원문과 다른 점:**  \r\n",
        "- 트레이닝 시에 나타나는 버그 수정  \r\n",
        "- huggingface 라이브러리에서 찾을 법한 것들을 미리 찾아서 설명 추가  \r\n",
        "- 코드 해설\r\n",
        "  \r\n",
        "**요구되는 개선 사항**\r\n",
        "- 오버피팅이 나타날 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY9S88ZKEChw"
      },
      "source": [
        "# Task: 버트로 문장 감성 분석 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkzjlkyQ9S5V",
        "outputId": "c09c3aa1-b232-4c91-a0a8-69c971e99649"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "\r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP4FFiH59fen",
        "outputId": "5ce8cbfe-dbec-4226-dc6e-9340c856c8e4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 24.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=62ba59fb7ad7457f29eb5c12a47718928f6400d59ca1bb6051a5d07d3e6e526d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hS7T17g9p25"
      },
      "source": [
        "wget: web -> colab "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9JjQse19uGP",
        "outputId": "e9ceaae6-3d76-44e5-e4cd-f8667a9a7f44"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=5b9b7d34b33a580c87c4fda12b092641c29dbb46dac3dbab963c4d544603af63\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfgcBa3z9u9v",
        "outputId": "74a2e501-f605-467a-9e71-889ae62f3ee6"
      },
      "source": [
        "import wget\r\n",
        "import os\r\n",
        "\r\n",
        "print('Downloading dataset...')\r\n",
        "\r\n",
        "# The URL for the dataset zip file.\r\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\r\n",
        "\r\n",
        "# Download the file (if we haven't already)\r\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\r\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bXpjTBe-TtB",
        "outputId": "52312166-ec2e-4a78-9cea-a0ee662ae8b0"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\r\n",
        "if not os.path.exists('./cola_public/'):\r\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO1PuarA-C1G"
      },
      "source": [
        "# Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNciLkRaQSYW"
      },
      "source": [
        "-  The Corpus of Linguistic Acceptability (CoLA) dataset for single sentence classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "UBuKHK45-A2n",
        "outputId": "35c29c3c-25dc-47ac-8e39-b55190af1af3"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load the dataset into a pandas dataframe.\r\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\r\n",
        "\r\n",
        "# Report the number of sentences.\r\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\r\n",
        "\r\n",
        "# Display 10 random rows from the data.\r\n",
        "df.sample(3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7480</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John did not like Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4395</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Mary not avoided Bill.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6637</th>\n",
              "      <td>m_02</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Into Jeeves sauntered the room.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  label label_notes                         sentence\n",
              "7480           sks13      1         NaN          John did not like Mary.\n",
              "4395            ks08      0           *           Mary not avoided Bill.\n",
              "6637            m_02      0           *  Into Jeeves sauntered the room."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6kVlI8E-WeC",
        "outputId": "8beab7a9-6656-4f02-cddb-394b8a9a4afa"
      },
      "source": [
        "print(df.sentence[1])\r\n",
        "print(len(df.label_notes))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One more pseudo generalization and I'm giving up.\n",
            "8551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwJfhh5AVTm"
      },
      "source": [
        "모델 학습 시, sentences, labels만 필요하다. 아래 같이 이들을 선택하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWXEQP9fAhrt",
        "outputId": "aefacb74-5d5e-4b9e-a312-0c01702a8bdd"
      },
      "source": [
        "sentences = df.sentence.values\r\n",
        "labels = df.label.values\r\n",
        "print(sentences[1])\r\n",
        "print(labels[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One more pseudo generalization and I'm giving up.\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6eXTeSaAqSY"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbeAVrOWC6Bm"
      },
      "source": [
        "- do_lower_case (bool, optional, defaults to True) : Whether or not to lowercase the input when tokenizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzXe5gblDR8J"
      },
      "source": [
        "- tokenizing for wordpiece embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9c523916f1934508834340818347160b",
            "2b6f5f3246ac4a5687892572c92fa021",
            "c93c88138cec49ec99aab0e363339634",
            "6b276f1155364f2690b624fedb3a15c1",
            "b0381fad6d1343bf892becbc917b02c6",
            "0b6996ca8e294ad998ad2d3b8d23d079",
            "fd74c9260ee94deaa8420fbe57f95717",
            "0a9c0672340a4c14a106779415fb3593"
          ]
        },
        "id": "gSX91aQ1ApE6",
        "outputId": "e8b88e1c-a038-47d0-ddd1-6624d04af4c9"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c523916f1934508834340818347160b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tYmLNcKDY5d"
      },
      "source": [
        "#### 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNpl8L_9DKFS",
        "outputId": "0e82f346-04cb-4f47-9e49-4bb8eac45f24"
      },
      "source": [
        "ex = 'I want to play the game'\r\n",
        "tokenizer.tokenize(ex)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'want', 'to', 'play', 'the', 'game']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkBPZNFTDaT4",
        "outputId": "7bee179e-70c5-4ab0-f49d-e5f8e7cbcae5"
      },
      "source": [
        "print(sentences[21])\r\n",
        "print(tokenizer.tokenize(sentences[21]))\r\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[21])))\r\n",
        "print(labels[21])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We yelled ourselves hoarse.\n",
            "['we', 'yelled', 'ourselves', 'hoarse', '.']\n",
            "[2057, 7581, 9731, 21221, 1012]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPjU40inEMJj"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCgjvcCtEPmO"
      },
      "source": [
        "- 1. CLS, SEP 붙이기  \r\n",
        "- 2. Padding  \r\n",
        "- 3. Vanila token과 'attention mask'가 있는 패딩 token 차이두기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qCS5K6PE_6w"
      },
      "source": [
        " - 데이터셋에는 여러 길이의 문장들이 있다. 버트 모델에게 이것을 처리할 수 있게 하기 위해, max_len을 설정한 뒤 패딩 처리를 한다.  \r\n",
        " -  Attention Mask는 1, 0로 이루어진 배열이고, 이것은 토큰이 패딩임과 패딩이 아님을 뜻한다. 이 Mask는 버트 메커니즘에서 \"셀프어텐션\"이 PAD 토큰을 문장의 해석에 포함시키지 않음을 뜻한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drQsJ0Q_F3nG"
      },
      "source": [
        "### 문장 최대 길이 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTJgTtqMEOpF",
        "outputId": "dea46bbe-3e8d-4f53-b639-db7411e6d4bc"
      },
      "source": [
        "max_len = 0\r\n",
        "for sen in sentences:\r\n",
        "    input_ids = tokenizer.encode(sen, add_special_tokens=True)\r\n",
        "    max_len = max(max_len, len(input_ids))\r\n",
        "\r\n",
        "print('가장 긴 문장 길이:',max_len)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "가장 긴 문장 길이: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IKfTqtZGYDw"
      },
      "source": [
        "### 패딩, CLS/SEP 첨가, 마스킹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOO0UVShJf4s"
      },
      "source": [
        "- return_tensors (str or TensorType, optional) –\r\n",
        "\r\n",
        "    - If set, will return tensors instead of list of python integers. Acceptable values are:\r\n",
        "\r\n",
        "    - 'tf': Return TensorFlow tf.constant objects.\r\n",
        "\r\n",
        "    - 'pt': Return PyTorch torch.Tensor objects.\r\n",
        "\r\n",
        "    - 'np': Return Numpy np.ndarray objects.  \r\n",
        "      \r\n",
        "https://huggingface.co/transformers/main_classes/tokenizer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U6DgI9QGfpp",
        "outputId": "bd4f77ef-31a9-4b95-f5d2-6e5d6babdbb4"
      },
      "source": [
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "문장집합 내의 각 문장에 대하여, 패딩+CLS/SEP첨가+마스킹 작업을 해준다.\r\n",
        "\"\"\"\r\n",
        "for sen in sentences:\r\n",
        "    encoded_sen = tokenizer.encode_plus(sen,add_special_tokens=True,max_length=50,return_attention_mask=True,return_tensors='pt', pad_to_max_length = True) # 'pt' = pytorch's tensor\r\n",
        "    input_ids.append(encoded_sen['input_ids']) # 이 같이 입력 아이디를 특정하지 않으면, token_type_ids, attn_mask도 출력된다.\r\n",
        "    attention_masks.append(encoded_sen['attention_mask']) \r\n",
        "    \"\"\"\r\n",
        "    9, 10번 출력 예:\r\n",
        "    'input_ids': tensor([[  101,  2028,  2062, 18404,  2236,  3989,  1998,  1045,  1005,  1049,\r\n",
        "          3228,  2039,  1012,   102,     0,     0,     0,     0,     0,     0,\r\n",
        "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n",
        "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n",
        "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]\r\n",
        "\r\n",
        "     'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
        "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
        "         0, 0]] \r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "print(len(input_ids))\r\n",
        "print(len(attention_masks))    "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8551\n",
            "8551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7l-kVDCNFP1",
        "outputId": "e22b7aa1-3f9e-484d-ad35-cb1c8901868b"
      },
      "source": [
        "input_ids[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
              "          2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKaqxguUMtvr",
        "outputId": "cc27b3ea-6152-450b-b356-d70b33562f93"
      },
      "source": [
        "input_ids = torch.cat(input_ids,dim=0)\r\n",
        "print(len(input_ids))\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "print(len(labels))\r\n",
        "labels = torch.tensor(labels)\r\n",
        "print(input_ids[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8551\n",
            "8551\n",
            "tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP-NK_vYNP9a"
      },
      "source": [
        "## 학습셋, 검증셋 분리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8OXJ75GNrRV"
      },
      "source": [
        "- TensorDataset은 인코딩된 문장집합을 (입력 문장 개수, 최대 문장 개수) 사이즈로 데이터셋을 만들어준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gOlRIfINR9D",
        "outputId": "3ee32ece-8e06-4a21-8a27-74b15ae22893"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "\r\n",
        "#dataset = TensorDataset(input_ids, labels)\r\n",
        "#dataset.tensors[0].size()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8551, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LmR1EwEN9hy"
      },
      "source": [
        "실제 사용할 코드는 아래의 것이다. 여기서 우리는 어텐션 마스킹도 첨가한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhX9GP9kNDbL",
        "outputId": "12ab6ffb-7f75-4658-b8b8-3e21c122cf6b"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "\r\n",
        "train_size = int(0.8*len(dataset))\r\n",
        "val_size = len(dataset)-train_size\r\n",
        "\r\n",
        "train_dataset, val_dataset = random_split(dataset,[train_size,val_size])\r\n",
        "\r\n",
        "print(f'학습셋 크기: {train_size}   검증셋 크기: {val_size}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습셋 크기: 6840   검증셋 크기: 1711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeQqeu9VOrkP"
      },
      "source": [
        "- DataLoader: 데이터셋을 배치 단위로 만들어줘서 모델이 학습하기에 용이하게 해준다.  \r\n",
        "- RandomSampler: 데이터로더가 배치를 랜덤하게 선택하게 해준다.  \r\n",
        "- SequentialSampler: 데이터로더가 배치를 연속적으로 선택하게 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ZKcQnkPAqM"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = BATCH_SIZE)\r\n",
        "valid_loader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = BATCH_SIZE)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-5gBMnP_NW"
      },
      "source": [
        "데이터로더 안에 들어있는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5bqwK5kPoEH",
        "outputId": "c05adadd-3704-40cf-e354-98e41165189a"
      },
      "source": [
        "print(type(train_loader.dataset.dataset.tensors))\r\n",
        "print(len(train_loader.dataset.dataset.tensors))\r\n",
        "print(train_loader.batch_size)\r\n",
        "print(train_loader.dataset.dataset.tensors[0].size())\r\n",
        "print(train_loader.dataset.dataset.tensors[1].size())\r\n",
        "print(train_loader.dataset.dataset.tensors[2].size())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "3\n",
            "16\n",
            "torch.Size([8551, 50])\n",
            "torch.Size([8551, 50])\n",
            "torch.Size([8551])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYeQ7oebQZUv"
      },
      "source": [
        "# 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbbkLhB5R3xV"
      },
      "source": [
        "- [AdamW에 대한 설명]('https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bc2emMRQaov",
        "outputId": "74d2fca7-4cbe-4b5c-e624-a7a3a8ac33e1"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \r\n",
        "                                                      num_labels = 2, # 우리는 문장을 긍부정으로 나누는 이진 분류를 수행\r\n",
        "                                                      output_attentions = False,\r\n",
        "                                                      output_hidden_states = False)\r\n",
        "\r\n",
        "model.cuda() # 모델을 GPU로 돌리게 함"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1aHZyaSz4P"
      },
      "source": [
        "# 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5VwmRQGRTwq"
      },
      "source": [
        "**Bert 원문에서 저자가 미세 조정fine-tuning 시 추천하는 값들**\r\n",
        "\r\n",
        "- Batch size: 16, 32\r\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\r\n",
        "- Number of epochs: 2, 3, 4  \r\n",
        "    - 우리는 차례로 16, 2e-5, 3를 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SyiHpeNThrS"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5,\r\n",
        "                  eps = 1e-8) # eps는 0으로 나누는 오류를 피하기 위해 사용"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D0lddG5Vn0L"
      },
      "source": [
        "[스케줄러 관한 자료]('https://www.python2.net/questions-699125.html')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ile70RfYTuEs"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "EPOCHS = 3\r\n",
        "total_steps = len(train_loader)*EPOCHS\r\n",
        "\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_training_steps=EPOCHS,num_warmup_steps=0) # num_warmup_steps는 디폴트값. 즉 2 개의 에폭을 돌리기 위해 따로 워밍업은 안하겠다."
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eR9UdDCRbgD",
        "outputId": "3dd9f7ed-f7df-4b14-a5d3-4d6a2d496562"
      },
      "source": [
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "seed_val = 2020\r\n",
        "\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "training_stats = []\r\n",
        "steps = []\r\n",
        "losses = []\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(0, EPOCHS):\r\n",
        "\r\n",
        "    total_train_loss = 0 # 매 에폭마다 초기화\r\n",
        "    model.train() # mode train\r\n",
        "\r\n",
        "    for step, batch in enumerate(train_loader):\r\n",
        "\r\n",
        "        if step % 10 ==0 & step != 0:\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_loader)))\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        위에서 확인했듯이, train_loader는 3 개의 원소로 구성된 튜플이다.\r\n",
        "        이것은 각각 \r\n",
        "        \r\n",
        "        train_loader[0] = input_ids\r\n",
        "        train_loader[1] = attention_mask\r\n",
        "        train_loader[2] = labels\r\n",
        "        를 담고 있다.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        batch_input_ids = batch[0].to(device) # gpu로 돌리려고\r\n",
        "        batch_input_mask = batch[1].to(device)\r\n",
        "        batch_labels = batch[2].to(device)\r\n",
        "\r\n",
        "        model.zero_grad()\r\n",
        "        # 아래 모델의 결과는 (loss, logits)의 튜플 형식\r\n",
        "        result = model(batch_input_ids,\r\n",
        "              token_type_ids = None, # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\r\n",
        "              attention_mask = batch_input_mask,\r\n",
        "              labels = batch_labels) # 모델 설명: https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification \r\n",
        "\r\n",
        "        # 위 모델에 담은 것들은 우리가 dataset에서 담은 것들이다: dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "        loss, logits = result[0], result[1]\r\n",
        "        total_train_loss += loss.item()\r\n",
        "        \r\n",
        "        losses.append(loss.item())\r\n",
        "        steps.append(step)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0) # grad explosion 방지 (optional)\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러 업데이트\r\n",
        "        scheduler.step()\r\n",
        "        if step % 10 ==0:\r\n",
        "            print(f'step: {step}    loss: {round(loss.item(),4)}')\r\n",
        "    avg_training_loss = total_train_loss/len(train_loader)\r\n",
        "\r\n",
        "    training_stats.append({\r\n",
        "        'epoch': epoch + 1,\r\n",
        "        'Training Loss': avg_training_loss})\r\n",
        "\r\n",
        "    print(f'\\n============avg_training_loss:  {avg_training_loss}============\\n')\r\n",
        "\r\n",
        "print('학습 끝 ^^')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 0    loss: 0.4807\n",
            "step: 10    loss: 0.6652\n",
            "step: 20    loss: 0.6378\n",
            "step: 30    loss: 0.5498\n",
            "step: 40    loss: 0.6081\n",
            "step: 50    loss: 0.6596\n",
            "step: 60    loss: 0.6293\n",
            "step: 70    loss: 0.649\n",
            "step: 80    loss: 0.5996\n",
            "step: 90    loss: 0.646\n",
            "step: 100    loss: 0.5586\n",
            "step: 110    loss: 0.6912\n",
            "step: 120    loss: 0.5785\n",
            "step: 130    loss: 0.7614\n",
            "step: 140    loss: 0.5319\n",
            "step: 150    loss: 0.5909\n",
            "step: 160    loss: 0.4997\n",
            "step: 170    loss: 0.7436\n",
            "step: 180    loss: 0.7286\n",
            "step: 190    loss: 0.6702\n",
            "step: 200    loss: 0.5976\n",
            "step: 210    loss: 0.5115\n",
            "step: 220    loss: 0.5981\n",
            "step: 230    loss: 0.6566\n",
            "step: 240    loss: 0.6243\n",
            "step: 250    loss: 0.4582\n",
            "step: 260    loss: 0.6176\n",
            "step: 270    loss: 0.5589\n",
            "step: 280    loss: 0.5239\n",
            "step: 290    loss: 0.5388\n",
            "step: 300    loss: 0.5915\n",
            "step: 310    loss: 0.6219\n",
            "step: 320    loss: 0.6459\n",
            "step: 330    loss: 0.5204\n",
            "step: 340    loss: 0.6747\n",
            "step: 350    loss: 0.7407\n",
            "step: 360    loss: 0.5706\n",
            "step: 370    loss: 0.5459\n",
            "step: 380    loss: 0.7281\n",
            "step: 390    loss: 0.6346\n",
            "step: 400    loss: 0.5429\n",
            "step: 410    loss: 0.7704\n",
            "step: 420    loss: 0.5879\n",
            "\n",
            "============avg_training_loss:  0.6223766900529372============\n",
            "\n",
            "step: 0    loss: 0.5798\n",
            "step: 10    loss: 0.521\n",
            "step: 20    loss: 0.5999\n",
            "step: 30    loss: 0.7436\n",
            "step: 40    loss: 0.538\n",
            "step: 50    loss: 0.6048\n",
            "step: 60    loss: 0.5711\n",
            "step: 70    loss: 0.6926\n",
            "step: 80    loss: 0.6252\n",
            "step: 90    loss: 0.5963\n",
            "step: 100    loss: 0.6856\n",
            "step: 110    loss: 0.5236\n",
            "step: 120    loss: 0.5152\n",
            "step: 130    loss: 0.5764\n",
            "step: 140    loss: 0.6703\n",
            "step: 150    loss: 0.5307\n",
            "step: 160    loss: 0.707\n",
            "step: 170    loss: 0.7507\n",
            "step: 180    loss: 0.6517\n",
            "step: 190    loss: 0.6107\n",
            "step: 200    loss: 0.5945\n",
            "step: 210    loss: 0.5805\n",
            "step: 220    loss: 0.5817\n",
            "step: 230    loss: 0.6272\n",
            "step: 240    loss: 0.6422\n",
            "step: 250    loss: 0.6648\n",
            "step: 260    loss: 0.612\n",
            "step: 270    loss: 0.6795\n",
            "step: 280    loss: 0.584\n",
            "step: 290    loss: 0.6012\n",
            "step: 300    loss: 0.5634\n",
            "step: 310    loss: 0.8699\n",
            "step: 320    loss: 0.7014\n",
            "step: 330    loss: 0.5561\n",
            "step: 340    loss: 0.6444\n",
            "step: 350    loss: 0.7678\n",
            "step: 360    loss: 0.5857\n",
            "step: 370    loss: 0.5815\n",
            "step: 380    loss: 0.6868\n",
            "step: 390    loss: 0.6721\n",
            "step: 400    loss: 0.6366\n",
            "step: 410    loss: 0.5787\n",
            "step: 420    loss: 0.5715\n",
            "\n",
            "============avg_training_loss:  0.6213204506958756============\n",
            "\n",
            "step: 0    loss: 0.663\n",
            "step: 10    loss: 0.7109\n",
            "step: 20    loss: 0.7001\n",
            "step: 30    loss: 0.5423\n",
            "step: 40    loss: 0.666\n",
            "step: 50    loss: 0.6842\n",
            "step: 60    loss: 0.4946\n",
            "step: 70    loss: 0.4279\n",
            "step: 80    loss: 0.6883\n",
            "step: 90    loss: 0.5464\n",
            "step: 100    loss: 0.5979\n",
            "step: 110    loss: 0.7455\n",
            "step: 120    loss: 0.6477\n",
            "step: 130    loss: 0.622\n",
            "step: 140    loss: 0.6872\n",
            "step: 150    loss: 0.6419\n",
            "step: 160    loss: 0.5632\n",
            "step: 170    loss: 0.5421\n",
            "step: 180    loss: 0.7524\n",
            "step: 190    loss: 0.6483\n",
            "step: 200    loss: 0.7267\n",
            "step: 210    loss: 0.6836\n",
            "step: 220    loss: 0.6197\n",
            "step: 230    loss: 0.7176\n",
            "step: 240    loss: 0.5187\n",
            "step: 250    loss: 0.5932\n",
            "step: 260    loss: 0.512\n",
            "step: 270    loss: 0.5339\n",
            "step: 280    loss: 0.5902\n",
            "step: 290    loss: 0.6852\n",
            "step: 300    loss: 0.7108\n",
            "step: 310    loss: 0.7171\n",
            "step: 320    loss: 0.6297\n",
            "step: 330    loss: 0.6399\n",
            "step: 340    loss: 0.4749\n",
            "step: 350    loss: 0.6915\n",
            "step: 360    loss: 0.5123\n",
            "step: 370    loss: 0.6627\n",
            "step: 380    loss: 0.5037\n",
            "step: 390    loss: 0.6915\n",
            "step: 400    loss: 0.7367\n",
            "step: 410    loss: 0.6187\n",
            "step: 420    loss: 0.6332\n",
            "\n",
            "============avg_training_loss:  0.6228998244226536============\n",
            "\n",
            "학습 끝 ^^\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhvpTrrdZ_Ss"
      },
      "source": [
        "# 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XsA3g76cKrM"
      },
      "source": [
        "검증에 앞서, 정확도를 구하는 함수를 짜보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J48zQHqqcKYq"
      },
      "source": [
        "def flat_acc(preds,labels):\r\n",
        "    pred_flat = np.argmax(preds,axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    return np.sum(pred_flat == labels_flat) // len(labels_flat)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R1ewbSnZ9YV",
        "outputId": "891d613a-9079-422c-a028-6cbceaa6314a"
      },
      "source": [
        "model.eval()\r\n",
        "\r\n",
        "total_eval_acc = 0\r\n",
        "total_eval_loss = 0\r\n",
        "val_losses = []\r\n",
        "total_val_steps = 0\r\n",
        "val_steps = []\r\n",
        "\r\n",
        "for epoch in range(0,EPOCHS):\r\n",
        "    cnt = 0\r\n",
        "    for batch in valid_loader:\r\n",
        "        \"\"\"\r\n",
        "        val_loader[0] = input_ids\r\n",
        "        val_loader[1] = attention_mask\r\n",
        "        val_loader[2] = labels\r\n",
        "        \"\"\"\r\n",
        "        batch_val_ids = batch[0].to(device)\r\n",
        "        batch_val_mask = batch[1].to(device)\r\n",
        "        batch_labels = batch[2].to(device)\r\n",
        "\r\n",
        "        with torch.no_grad(): # torch.no_grad()로 감싸는 이유는 가중치들이 requires_grad=True이지만 autograd에서는 이를 추적할 필요가 없기 때문이다.\r\n",
        "            result = model(batch_val_ids,\r\n",
        "                           token_type_ids = None,\r\n",
        "                           attention_mask = batch_val_mask, \r\n",
        "                           labels = batch_labels)\r\n",
        "            loss, logits = result[0], result[1]\r\n",
        "\r\n",
        "        total_eval_loss += loss.item()\r\n",
        "        val_losses.append(loss.item())\r\n",
        "        val_steps.append(cnt)\r\n",
        "        cnt += 1\r\n",
        "        \r\n",
        "\r\n",
        "        # 출력을 위해 텐서를 cpu의 넘파이로 옮김\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = batch_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "        total_eval_acc += flat_acc(logits, label_ids)\r\n",
        "    \r\n",
        "    avg_eval_loss = total_eval_loss / len(valid_loader)\r\n",
        "    avg_eval_acc = total_eval_acc / len(valid_loader)\r\n",
        "    print(f'\\n============평균 검증 정확도:  {avg_eval_acc}============\\n')\r\n",
        "    print(f'\\n============평균 검증 손실:  {avg_eval_loss}============\\n')\r\n",
        "\r\n",
        "    training_stats.append({\r\n",
        "        'Val_loss':avg_eval_loss,\r\n",
        "        'Val_acc':avg_eval_acc\r\n",
        "    })\r\n",
        "\r\n",
        "print('검증도 끝 ^^')\r\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============평균 검증 정확도:  0.009345794392523364============\n",
            "\n",
            "\n",
            "============평균 검증 손실:  0.6172799381697289============\n",
            "\n",
            "\n",
            "============평균 검증 정확도:  0.018691588785046728============\n",
            "\n",
            "\n",
            "============평균 검증 손실:  1.2345598763394579============\n",
            "\n",
            "\n",
            "============평균 검증 정확도:  0.028037383177570093============\n",
            "\n",
            "\n",
            "============평균 검증 손실:  1.8518398145091868============\n",
            "\n",
            "검증도 끝 ^^\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh74rf52jG8p"
      },
      "source": [
        "# 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "d0pDjg1RiM-h",
        "outputId": "fe215804-5e98-429e-948e-bd8471be7d2e"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(steps,losses,'b--')\r\n",
        "plt.plot(val_steps,val_losses,'r-')\r\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Kop7bDkB2l"
      },
      "source": [
        "# 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl80upW9kLh4"
      },
      "source": [
        "- 따로 준비해둔 516 개의 문장으로 구성된 테스트셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRD_Rk4IkC2-",
        "outputId": "82373b8c-42c6-47e9-dfff-844110253560"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\r\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\r\n",
        "print(df.columns)\r\n",
        "print(df.sentence[1])"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n",
            "Index(['sentence_source', 'label', 'label_notes', 'sentence'], dtype='object')\n",
            "They claimed they had settled on something, but it wasn't clear what they had settled on.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxctmXzzkcW8"
      },
      "source": [
        "앞에서 했던 전처리를 여기서도 동일하게 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVz6E90MkKMU",
        "outputId": "7ebb33c3-ee9f-4eb3-8103-8ad85042e6d3"
      },
      "source": [
        "sentences = df.sentence.values\r\n",
        "labels = df.label.values\r\n",
        "\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "for sen in sentences:\r\n",
        "    encoded_sen = tokenizer.encode_plus(sen,\r\n",
        "                                        add_special_tokens = True,\r\n",
        "                                        max_length=64,\r\n",
        "                                        return_attention_mask=True,\r\n",
        "                                        pad_to_max_length=True,\r\n",
        "                                        return_tensors = 'pt')\r\n",
        "    input_ids.append(encoded_sen['input_ids'])\r\n",
        "    attention_masks.append(encoded_sen['attention_mask'])\r\n",
        "\r\n",
        "#list->tensor\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "pred_data = TensorDataset(input_ids,attention_masks,labels)\r\n",
        "pred_sampler = SequentialSampler(pred_data)\r\n",
        "pred_loader = DataLoader(pred_data,\r\n",
        "                         sampler=pred_sampler,\r\n",
        "                         batch_size=BATCH_SIZE)\r\n"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdarUevXmOZV",
        "outputId": "5bacc4d3-3b40-4a37-c289-0091618553fc"
      },
      "source": [
        "model.eval()\r\n",
        "\r\n",
        "predictions=[]\r\n",
        "labels =[]\r\n",
        "\r\n",
        "for batch in pred_loader:\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        result = model(b_input_ids, \r\n",
        "                       token_type_ids = None, \r\n",
        "                       attention_mask = b_input_mask)\r\n",
        "    logits = result[0]\r\n",
        "    \r\n",
        "    #gpu->cpu\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    labels_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "    predictions.append(logits)\r\n",
        "    labels.append(labels_ids)\r\n",
        "\r\n",
        "print('테스트 완료 ^^')\r\n",
        "print(len(logits),len(labels),len(predictions))\r\n",
        "print(predictions[1])\r\n",
        "print(labels[1])\r\n",
        "print(len(predictions[1]))\r\n",
        "print(len(labels[1]))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 완료 ^^\n",
            "4 17 17\n",
            "[[-5.22860140e-02  9.42214429e-01]\n",
            " [ 1.58029467e-01  4.92303431e-01]\n",
            " [ 3.89743745e-02  9.97587860e-01]\n",
            " [ 1.23240151e-01  6.33725524e-01]\n",
            " [ 1.12563595e-01  6.45310462e-01]\n",
            " [ 1.25449568e-01  7.47154891e-01]\n",
            " [ 3.11109442e-02  8.56492281e-01]\n",
            " [-1.29896194e-01  7.45413423e-01]\n",
            " [-4.34066961e-03  9.45772171e-01]\n",
            " [ 1.88685376e-02  9.40793931e-01]\n",
            " [ 5.04645333e-02  7.78768241e-01]\n",
            " [ 1.50537819e-01  6.19503260e-01]\n",
            " [ 7.23662004e-02  9.31154668e-01]\n",
            " [-3.77127677e-02  7.06097841e-01]\n",
            " [-1.70071684e-02  6.94440007e-01]\n",
            " [ 2.57898960e-02  6.51734233e-01]\n",
            " [-5.68646826e-02  5.02504230e-01]\n",
            " [ 5.28035127e-02  9.59193170e-01]\n",
            " [-6.93192780e-02  6.73806310e-01]\n",
            " [-5.65236248e-02  6.88705385e-01]\n",
            " [-4.40158188e-01 -3.36946100e-02]\n",
            " [-3.25605795e-02  7.45551944e-01]\n",
            " [ 6.89027607e-02  8.03788602e-01]\n",
            " [ 1.61556393e-01  1.08336437e+00]\n",
            " [-1.07564649e-03  8.67509246e-01]\n",
            " [-1.07564649e-03  8.67509246e-01]\n",
            " [ 8.10913295e-02  7.74565995e-01]\n",
            " [-3.94226471e-03  8.23304415e-01]\n",
            " [-5.42662153e-03  6.66237652e-01]\n",
            " [-4.48360555e-02  8.34668636e-01]\n",
            " [-3.94226471e-03  8.23304415e-01]\n",
            " [-2.85726022e-02  9.66319025e-01]]\n",
            "[1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1]\n",
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdZulc0dsWzu",
        "outputId": "80c0be33-1665-4353-f835-807e39dc0b50"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxQstCVtxBBn",
        "outputId": "2a58a70a-543d-4fdc-84ef-b22811487aa5"
      },
      "source": [
        "label_result=[]\r\n",
        "for lb in labels:\r\n",
        "    label_result.append(np.sum(lb,axis=0))\r\n",
        "print(label_result)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 22, 19, 23, 21, 19, 20, 28, 24, 17, 23, 24, 19, 26, 26, 21, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7LvtI0iotI9"
      },
      "source": [
        "### 테스트 측정 결과  \r\n",
        "  \r\n",
        "- [MCC 설명]('https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTL6A69cvT8v",
        "outputId": "4030bd80-7357-4dae-ed86-9449714104fa"
      },
      "source": [
        "prediction_set = []\r\n",
        "print('예측 벡터\\n')\r\n",
        "for pred in predictions:\r\n",
        "    suma = np.sum(pred,axis=0)\r\n",
        "    prediction_set.append(suma)\r\n",
        "print(prediction_set)\r\n",
        "\r\n",
        "prediction_set2 = []\r\n",
        "for p in prediction_set:\r\n",
        "    prediction_set2.append(p[1])\r\n",
        "print(prediction_set2)    \r\n",
        "\r\n",
        "result=[]\r\n",
        "for i in range(17):\r\n",
        "    if prediction_set2[i] - label_result[i] >4: # 4는 내가 임의로 정한 것\r\n",
        "        result.append(0)\r\n",
        "    elif prediction_set2[i] - label_result[i] <4:\r\n",
        "        result.append(1)\r\n",
        "\r\n",
        "one=0\r\n",
        "zero=0\r\n",
        "for j in result:\r\n",
        "    if j == 1:\r\n",
        "        one+=1\r\n",
        "    else:\r\n",
        "        zero+=1\r\n",
        "\r\n",
        "print(one,zero)\r\n",
        "print('accuracy: ',round((one/(one+zero))*100,3),'%')\r\n"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 벡터\n",
            "\n",
            "[array([ 0.4662616, 22.678963 ], dtype=float32), array([ 0.28620893, 24.375107  ], dtype=float32), array([ 1.275849, 21.919443], dtype=float32), array([ 1.0069468, 25.400478 ], dtype=float32), array([ 1.6942196, 26.534948 ], dtype=float32), array([ 0.7965374, 20.480465 ], dtype=float32), array([ 0.58308345, 22.063683  ], dtype=float32), array([ 1.5024811, 21.08399  ], dtype=float32), array([ 0.9781708, 21.15051  ], dtype=float32), array([ 1.9375188, 20.220636 ], dtype=float32), array([ 1.8616086, 20.06676  ], dtype=float32), array([ 1.9093299, 21.456003 ], dtype=float32), array([ 0.9133444, 22.061832 ], dtype=float32), array([ 1.8105123, 21.255209 ], dtype=float32), array([ 0.68716323, 22.898623  ], dtype=float32), array([ 1.0431023, 24.077984 ], dtype=float32), array([0.35804784, 3.2558308 ], dtype=float32)]\n",
            "[22.678963, 24.375107, 21.919443, 25.400478, 26.534948, 20.480465, 22.063683, 21.08399, 21.15051, 20.220636, 20.06676, 21.456003, 22.061832, 21.255209, 22.898623, 24.077984, 3.2558308]\n",
            "16 1\n",
            "accuracy:  94.118 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPnfCyb0_0sc"
      },
      "source": [
        "# References & Copy\r\n",
        "  \r\n",
        "[1] https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=EKOTlwcmxmej  \r\n",
        "[2] https://mccormickml.com/2019/07/22/BERT-fine-tuning/  \r\n",
        "[3] https://huggingface.co/transformers/main_classes/tokenizer.html  \r\n",
        "[4] https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html\r\n"
      ]
    }
  ]
}